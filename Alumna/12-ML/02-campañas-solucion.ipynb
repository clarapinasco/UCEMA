{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "import sklearn \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.rc('xtick', labelsize=10)     \n",
    "plt.rc('ytick', labelsize=10)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'clientes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14824/1578147231.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'clientes.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m';'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Tamaño del Dataset: {df.shape}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    700\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'clientes.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('clientes.csv', delimiter=';')\n",
    "print(f\"Tamaño del Dataset: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante aclarar que para la <font color='green'>reproducibilidad de los resultados</font> . Sobre todo para empresas de seguros que necesitan repetir el pricing para una cartera con un riesgo determinado, deben usar una semilla y debe ser la misma para dar los mismos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(100)\n",
    "random_state = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "Una entidad bancaria acaba de realizar una campaña de marketing, cuyo objetivo buscaba lograr que los clientes contactados depositaran sus ahorros a plazo fijo. Los resultados fueron <font color='red'>peor</font>  de lo esperado.\n",
    "Esta campaña se enfocó en un 10% de la cartera total de clientes del banco.\n",
    "\n",
    "El banco contrata nuestros servicios como científic@ de datos y nos comunica los siguintes objetivos:\n",
    "\n",
    "* Repetir una o más campañas en el transcurso de los siguientes 18 meses. \n",
    "* Maximizar la tasa de conversión de las mismas y entender los factores que influyen en esta tasa.\n",
    "\n",
    "\n",
    "Nuestra tarea consiste en ayudar al banco a cumplir sus objetivos.\n",
    "\n",
    "**Comentario Inicial**\n",
    "\n",
    "El problema es de tipo comercial en donde una campaña asegura la conversión o no del cliente. Para esto también es importante determinar la cantidad de días que pasan para llegar a la conversión. Entendiendo entonces que existe un número óptimo de campañas dentro de los 18 meses (a ejemplo: si un cliente convierte a 90 días del contacto de la campaña, sólo podré hacer 6 campañas en 18 meses)\n",
    "\n",
    "*Pasos a seguir*:\n",
    "\n",
    "1. Preprocesamiento\n",
    "2. Exploracion de la data e interpretacion\n",
    "3. Regresion logistica\n",
    "4. Arbol D3\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "Target = {Realizó.plazo.fijo}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Metadata\n",
    "\n",
    "#### Datos clientes\n",
    "\n",
    "El banco nos provee la lista de los ~4.5K clientes (\"clientes.csv\") que fueron contactados durante esta última campaña y nos informa que por el momento NO nos proveerá de mas datos que estos.\n",
    "\n",
    "1. `age`: edad del clietne\n",
    "2. `job`: tipo de trabajo\n",
    "3. `marital`: estado civil\n",
    "4. `education`: nivel de educación\n",
    "5. `default`: indica si el cliente registra algún default crediticio\n",
    "5. `balance`: saldo en dólares de la caja de ahorro del cliente\n",
    "6. `housing`: indica si el cliente posee un préstamo hipotecario\n",
    "7. `loan`: indica si el cliente posee algún préstamo personal\n",
    "\n",
    "#### Datos del último contacto de la campaña actual\n",
    "9. `contact`: canal de contacto\n",
    "10. `day`: día de último contacto\n",
    "11. `month`: mes de último contacto\n",
    "12. `duration`: duracion del último contacto\n",
    "13. `campaign`: cantidad de contactos durante la campaña\n",
    "\n",
    "#### Datos campaña previa\n",
    "14. `pdays`: días transcurridos desde el último contacto por una campaña previa\n",
    "15. `previous`: cantidad de contactos previous a esta campaña\n",
    "16. `poutcome`: resultado de la campaña previa\n",
    "\n",
    "#### Resultado campaña actual\n",
    "17. `y` - Indica si el cliente realizó depósito a plazo fijo(binaria: 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.previous.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observo las medidas de estadística descritptiva de las variables numericas. La edad promedio es de 41 años, el balance promedio de cliente es 1422, el día promedio de contacto es el día 155, la duración promedio del ultimo contacto es de 259, la cantidad de contactos promedio es de 2.79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será interesante estudiar cada variable por separado. Entendiendo las distrubciones a fin de entender que factores influyen en las campañas. \n",
    "* **Distribucion del target** `y`  determinar la conversión del cliente es nuestro target, por lo tanto complementarlo en el analisis de dato a las variables anteriores nos permitirá entender cómo se compone nuestra muestra.\n",
    "\n",
    "* **Edad y rango etario** la edad es una variable importante a la hora de segmentar productos. Por lo tanto enfocaremos cómo punto de partida la distribución del target en función de  `age` .\n",
    "\n",
    "* **Trabajo** El tipo de trabajo puede determinar la compra o no de productos financieros, en este caso entendemos al plazo fijo cómo un tipo de ahorro en un activo libre de riesgo.\n",
    "\n",
    "* **Estacionalidad**: `days` y `month` los días de la semana y los meses determinaran la estacionalidad tal vez propia del producto (Si este caso fuese Argentina una hipotesis sería que los meses de aguinaldo la tasa de conversión podría ser mayor). \n",
    "\n",
    "* **Variables Económicas** `loan`, `balance`y `default`  seran también interesantes para segmentar. Será interesante hacer visualizaciones y analisis bivariados.\n",
    "\n",
    "* Medios: `campaign` y  `contact`  Respecto al canal de campaña y las caracteristicas de contacto, establecer el comportamiento descriptivo de la data permite entender la operatividad de las llamadas y complementar luego a los modelos de predicción para elaborar una campaña con mayor probabilidad de conversión.\n",
    "\n",
    "* Segmento target social: `marital`, `education`, no permitiran determinar la variables socioeconómicas de los clientes, sumado a las **data driven** de la campaña de marketing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap: Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8,6\n",
    "sns.heatmap(df.corr(),cmap='coolwarm',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa una correlacion de 0.58 entre `pdays` y  `previous`, es decir que los días transcurridos entre el último contacto y la cantidad de contactos previos se relacionan positivamente. Ampliaremos esta relación, pero entendemos que en los posteriores modelos nos quedaremos sólo con una de la dos variables, tratando de evitar la multicolinealidad. Entendiendo que un modelo más simple para una cuestión interpretativa es mejor (*Occam's razor*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "Chequeos si existen valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Porcentaje de nulos por variable en df\n",
    "(df.isnull().sum().sort_values()/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset no posee faltantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.month = pd.to_datetime(df.month, format='%b').dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierto la columna mes al tipo datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 6,6\n",
    "paleta = [\"#fc8d59\",\"#3288bd\"]\n",
    "\n",
    "df['y'].value_counts()\n",
    "sns.countplot(x='y', data=df, palette=paleta)\n",
    "plt.xlabel(\"Dépositó el plazo fijo\") \n",
    "plt.ylabel(\"Cantidad de Clientes\")\n",
    "plt.title(\"Distribución del Target\")  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "PF_NO = len(df[df['y']=='no'])\n",
    "PF_YES = len(df[df['y']=='yes'])\n",
    "no_plazofijo_porciento =( PF_NO / (PF_NO + PF_YES) * 100)\n",
    "si_plazofijo_porciento= (PF_YES / (PF_NO + PF_YES) * 100)\n",
    "print('Porcentajes de plazo fijo en la muestra:', si_plazofijo_porciento)\n",
    "print('Porcentajes de NO plazo fijo en la muestra:', no_plazofijo_porciento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una distribución no equilibrada de las clases por lo cual tendremos que evaluar si realizamos algun método de sobresampleo o no en el futuro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupo por target para ver la media según si hicieron el plazo fijo o no lo hicieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los clientes que obtuvieron un plazo fijo tienen una edad media y un balance no es mucho mayor que los que no sacaron el plazo fijo. La diferencia en el valor de tendencia central se observa en la duración del ultimo contacto, la cual es mayor en los que convirtieron de los que no, y una cantidad mayor de días transcurridos desde el último contacto cómo también mayor cantidad de contactos previos.\n",
    "\n",
    "Cómo primera intuición a validar con nuestros modelos observamos una relación positiva entre convertir (realizar el deposito) y las variables `duration`  y cantidad de contactos previos `previous`. Entendiendo que el promedio de los que convierten es 68 días entre llamada y llamada, cabe destacar que el promedio de  `pdays` días transcurridos es mayor en aquellos clientes que no convierten, teniendo que encontrar el punto óptimo entre cantidad de contactos en 180 días y el tiempo entre contacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso a numerico el target para construir una correlacion pero viendo con que variable correlaciona\n",
    "df1.y = df1.y.map({'no':0, 'yes':1}).astype('int32')\n",
    "\n",
    "corr = df1.corr()\n",
    "corr.style.background_gradient(cmap='PuBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration\n",
    "Teniendo en cuenta la variable Y, en la matriz de correlacion observamos la variable `duration`  es la que más se correlaciona cón el target. Habrá que realizar el analisi con la variable duracion transformada y sin, para ver si esta correlacion nos imposibilitan la capacidad de generalizar del modelo.  Un posible approach sea generar bins respecto a la duración separandola en cuartiles. Ahora bien hay que tener en cuenta dos perspectivas de la variable `duration` , por un lado puede darnos perspectiva de cómo deben ser las caracteristicas de las llamadas, esta data se utiliza en Speech Analytics. Por otro lado, hay que entender que puede ser útil cómo variable historica, pero en un set de datos nuevos (clientes aún no llamados) existe la probabilidad que no tenga aún esta variable. Estudiaremos esto en la parte de Feature Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paleta = [\"#fc8d59\",\"#3288bd\"]\n",
    "yes_df = df[df['y'] == 'yes']\n",
    "no_df = df[df['y'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por la reproducibilidad de los graficos prefiero siempre GGPLOT a estos códigos de seaborn y matplot\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n",
    "\n",
    "\n",
    "sns.boxplot(y='duration', x='y', data=df, palette=paleta, ax = ax1)\n",
    "ax1.set_xlabel('Llamadas', fontsize=10)\n",
    "ax1.set_ylabel('Duración', fontsize=10)\n",
    "ax1.set_title('Boxplot Duracion', fontsize=10)\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "sns.distplot(yes_df['duration'],color='#3288bd', ax = ax2)\n",
    "sns.distplot(no_df['duration'],color = '#fc8d59', ax = ax2) \n",
    "ax2.set_xlabel('Duracion del ultimo Contacto', fontsize=10)\n",
    "ax2.set_ylabel('Ocurrencia', fontsize=10)\n",
    "ax2.set_title('Frecuencia de datos de la variable Duracion', fontsize=10)\n",
    "ax2.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('1º Cuartil: ', yes_df['duration'].quantile(q = 0.25))\n",
    "print('2º Cuartil: ', yes_df['duration'].quantile(q = 0.50))\n",
    "print('3º Cuartil: ', yes_df['duration'].quantile(q = 0.75))\n",
    "print('4º Cuartil: ', yes_df['duration'].quantile(q = 1.00))   \n",
    "print('La duración arriba de: ', yes_df['duration'].quantile(q = 0.75) + \n",
    "                      1.5*(yes_df['duration'].quantile(q = 0.75) - yes_df['duration'].quantile(q = 0.25)), 'son outliers para clientes que depositaron el plazo fijo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('1º Cuartil: ', no_df['duration'].quantile(q = 0.25))\n",
    "print('2º Cuartil: ', no_df['duration'].quantile(q = 0.50))\n",
    "print('3º Cuartil: ', no_df['duration'].quantile(q = 0.75))\n",
    "print('4º Cuartil: ', no_df['duration'].quantile(q = 1.00))\n",
    "print('La duración arriba de: ', no_df['duration'].quantile(q = 0.75) + \n",
    "                      1.5*(no_df['duration'].quantile(q = 0.75) - no_df['duration'].quantile(q = 0.25)), 'son outliers para los clientes que no depositaron el plazo fijo ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edad y Rango etario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Edad Max: ', df['age'].max())\n",
    "print('Mediana de la edad: ', df['age'].median())\n",
    "print('Promedio de la edad: ', df['age'].mean())\n",
    "print('Edad Min: ', df['age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,6\n",
    "sns.countplot(x = 'age', data = df,color = \"#607d8b\")\n",
    "plt.xlabel(\"Edad\") \n",
    "plt.ylabel(\"Cantidad de Clientes\")\n",
    "plt.title(\"Distribución de la edad en la muestra\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots( figsize = (13, 5))\n",
    "\n",
    "\n",
    "sns.boxplot(y='age', x='y', data=df, palette=paleta, ax = ax1)\n",
    "ax1.set_xlabel('Conversión', fontsize=10)\n",
    "ax1.set_ylabel('Edad', fontsize=10)\n",
    "ax1.set_title('Boxplot Edad', fontsize=10)\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el gráfico de edad tiene una asimetria hacia la izquierda.\n",
    "\n",
    "¿Qué pasa si cruzamos edad con duración? ¿Donde se concentran la mayor cantidad de valores en toda la muestra separando entonces conversión de no conversión?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='age', y='duration', data=yes_df[( yes_df['duration'] < 1497) & (yes_df['age'] < 60)], kind='kde', color='#3288bd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='age', y='duration', data=no_df[(no_df['duration'] < 1497) & (no_df['age'] < 60)], kind='kde', color=\"#fc8d59\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el centro de masa cambia en duración y no respecto a la edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del no_df\n",
    "del yes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupacion por rango etareo\n",
    "Agrupo las edades por decadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [df]\n",
    "for column in lst:\n",
    "    column.loc[column[\"age\"] < 30,  'grupo_edad'] = 20\n",
    "    column.loc[(column[\"age\"] >= 30) & (column[\"age\"] <= 39), 'grupo_edad'] = 30\n",
    "    column.loc[(column[\"age\"] >= 40) & (column[\"age\"] <= 49), 'grupo_edad'] = 40\n",
    "    column.loc[(column[\"age\"] >= 50) & (column[\"age\"] <= 59), 'grupo_edad'] = 50\n",
    "    column.loc[column[\"age\"] >= 60, 'grupo_edad'] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_por_edad = pd.crosstab(df['y'],df['grupo_edad'])\n",
    "total_por_edad.loc['Total',:]= total_por_edad.sum(axis=0)\n",
    "total_por_edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_edad = pd.crosstab(df['y'],df['grupo_edad']).apply(lambda x: x/x.sum() * 100)\n",
    "crosstab_edad = crosstab_edad.transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = pd.DataFrame(df['grupo_edad'].value_counts())\n",
    "age['% Decada'] = age['grupo_edad']*100/age['grupo_edad'].sum()\n",
    "age['% Conversion'] = crosstab_edad['yes']\n",
    "age.drop('grupo_edad',axis = 1,inplace = True)\n",
    "\n",
    "age['age'] = [30,40,50,20,60]\n",
    "age = age.sort_values('age',ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8,6\n",
    "sns.set_style(\"darkgrid\")\n",
    "plot_age = age[['% Conversion','% Decada']].plot(kind = 'bar',color = ('#2ca25f','#b2e2e2'))\n",
    "plt.xlabel('Edad del grupo')\n",
    "plt.ylabel('Tasa de Conversión sobre el total')\n",
    "plt.xticks(np.arange(5), ('<30', '30-39', '40-49', '50-59', '60+'),rotation = 'horizontal')\n",
    "plt.title('Conversión vs Rango Etareo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del total_por_edad\n",
    "del crosstab_edad\n",
    "del age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apuntar las llamadas a los extremos.\n",
    "\n",
    "Cuando observamos la conversión por grupo etareo cambia la intuición al ver el total de las edades. Observamos que la conversión de los clientes mayores a 60 años es la más alta llegando a un 30% y a su vez aproximadamente un 15% de las conversiones son del extremo inferior, aquellos clientes con menos de 30 años.\n",
    "\n",
    "Si dentro de la literatura financiera entendemos que un plazo fijo es un activo libre de riesgo (nunca en argentina), tendría sentido que los extremos etareos tengan aversión al riesgo, los jovenes porque pueden ahorrar para la educación y los mayores porque necesitan asegurar su retiro. \n",
    "\n",
    "Este grafico nos muestra que las llamadas del banco están orientadas al rango 30-40 y 40-49, con esta simple descripción de datos haría la primera recomendación de apuntar las llamadas a los extremos etareos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14,6\n",
    "trabajos = sns.countplot(x = 'job', data = df,\n",
    "              order = df['job'].value_counts().index)\n",
    "plt.xlabel(\"Trabajos\")\n",
    "plt.ylabel(\"Cantidad de Clientes\")\n",
    "plt.title(\"Distribucion de personas por trabajo\") \n",
    "plt.show(trabajos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(df.loc[df[\"job\"] == \"unknown\"].index) #Son solo 38 observaciones que para ver la distribucion del trabajo no me sirven\n",
    "label_value = df1[\"job\"].value_counts().to_dict()\n",
    "# Creo los labels usando a list comprehesion\n",
    "labels = [\"{} tiene {} obs\".format(class_, obs) for class_, obs in label_value.items()]\n",
    "# Creo colores por cantidad de trabajos\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "plt.figure(figsize = (18, 10))\n",
    "squarify.plot(sizes = label_value.values(), label = labels,  color = colors, alpha = 0.8)\n",
    "plt.title(\"Cantidad de trabajos por personas\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_trabajo = pd.crosstab(df['y'],df['job']).apply(lambda x: x/x.sum() * 100)\n",
    "cross_tab_trabajo = cross_tab_trabajo.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trabajo = cross_tab_trabajo['yes'].sort_values(ascending = True).plot(kind ='barh', color = \"#2ca25f\",\n",
    "                                                                           figsize = (12,6))\n",
    "                                                                               \n",
    "plt.title('Tasa de conversion por trabajo')\n",
    "plt.xlabel('Tasa de conversion')\n",
    "plt.ylabel('Tipo de trabajo')\n",
    "\n",
    "# Por estas funciones prefiero ggplot\n",
    "for rec, label in zip(trabajo.patches,\n",
    "                      cross_tab_trabajo['yes'].sort_values(ascending = True).round(1).astype(str)):\n",
    "    trabajo.text(rec.get_width()+0.8, \n",
    "                  rec.get_y()+ rec.get_height()-0.5, \n",
    "                  label+'%', \n",
    "                  ha = 'center', \n",
    "                  va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistentemente con la edad, las personas con mayor tasa de conversión son estudiantes o personas retiradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cross_tab_trabajo\n",
    "del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax3) = plt.subplots(nrows = 1, ncols = 2, figsize = (15,6))\n",
    "\n",
    "\n",
    "sns.countplot(x='month', data=df, ax = ax2)\n",
    "ax2.set_xlabel('Months', fontsize = 10)\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Meses del año')\n",
    "ax2.tick_params()\n",
    "\n",
    "sns.countplot(x='day', data=df, ax = ax3)\n",
    "ax3.set_xlabel('Day of Week', fontsize = 10)\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_title('Dia de la semana')\n",
    "ax3.tick_params()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax3) = plt.subplots(nrows = 1, ncols = 2, figsize = (15,6))\n",
    "\n",
    "\n",
    "sns.countplot(x=\"month\", hue=\"y\", palette=paleta, data=df, ax = ax2)\n",
    "ax2.set_xlabel('Months', fontsize = 10)\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Meses del año')\n",
    "ax2.tick_params()\n",
    "\n",
    "sns.countplot(x='day', hue=\"y\", palette=paleta, data=df, ax = ax3)\n",
    "ax3.set_xlabel('Day of Week', fontsize = 10)\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_title('Dia de la semana')\n",
    "ax3.tick_params()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca grafiqué cantidad de llamadas con conversion y cantidad que no. Sería interesante graficar el % de conversión por mes y por día de la semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_totales= pd.crosstab(df['y'],df['month'])\n",
    "mes_totales_t  = mes_totales.T\n",
    "mes_totales_t[\"total\"] = mes_totales.T.sum(axis=1)\n",
    "mes_totales_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crooss_tab_mes = pd.crosstab(df['y'],df['month']).apply(lambda x: x/x.sum() * 100)\n",
    "crooss_tab_mes = crooss_tab_mes.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_cant = pd.DataFrame(df['month'].value_counts())\n",
    "mes_cant['% Llamadas totales'] = mes_cant['month']*100/mes_cant['month'].sum()\n",
    "mes_cant['% Conversion'] = crooss_tab_mes['yes']\n",
    "mes_cant.drop('month',axis = 1,inplace = True)\n",
    "\n",
    "#me quedó el mes cómo columna con el cross tab y desordenado\n",
    "mes_cant['mes'] = [5,7,8,6,11,4,2,1,10,9,3,12]\n",
    "mes_cant = mes_cant.sort_values('mes',ascending = True)\n",
    "#mes_cant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,6\n",
    "\n",
    "plot_month = mes_cant[['% Conversion','% Llamadas totales']].plot(kind ='line',color = ('#66c2a4','#3288bd'),                                                          marker = 'o')\n",
    "\n",
    "plt.title('Conversion vs Porcentaje de llamadas')\n",
    "plt.ylabel('Tasa de conversión y llamadas')\n",
    "plt.xlabel('Meses')\n",
    "\n",
    "ticks = np.arange(1,13,1)\n",
    "#plt.xticks(ticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_cant1 = mes_cant.copy()\n",
    "mes_cant1.loc['Total',\"% Llamadas totales\"]=  mes_cant1[\"% Llamadas totales\"].sum(axis=0)\n",
    "mes_cant1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"La mayoría de las llamadas se realizaron en el mes de mayo, representando el %30  del total de llamadas\")\n",
    "mes_cant[mes_cant['% Llamadas totales'] == mes_cant['% Llamadas totales'].max()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"El maximo de % Conversion  se encuentra en el mes 10 con un % 46 de conversion de llamadas pero sólo un % 1,76 de llamadas totales\")\n",
    "mes_cant[mes_cant['% Conversion'] == mes_cant['% Conversion'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "La recomendación sería hacer más campañas en el mes 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libero espacio del disco\n",
    "del crooss_tab_mes\n",
    "del mes_cant\n",
    "del mes_cant1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crooss_tab_dia = pd.crosstab(df['y'],df['day']).apply(lambda x: x/x.sum() * 100)\n",
    "crooss_tab_dia = crooss_tab_dia.transpose()\n",
    "dia_cant = pd.DataFrame(df['day'].value_counts())\n",
    "dia_cant['% Llamadas totales por dia'] = dia_cant['day']*100/dia_cant['day'].sum()\n",
    "dia_cant['% Conversion diario'] = crooss_tab_dia['yes']\n",
    "dia_cant['dias'] = dia_cant.index\n",
    "\n",
    "\n",
    "dia_cant = dia_cant.sort_values('dias',ascending = True)\n",
    "\n",
    "rcParams['figure.figsize'] = 10,6\n",
    "\n",
    "plot_dias = dia_cant[['% Conversion diario','% Llamadas totales por dia']].plot(kind ='line',color = ('#006d2c','#b2e2e2'),                                                          marker = 'o')\n",
    "\n",
    "plt.title('Conversion vs Porcentaje de llamadas')\n",
    "plt.ylabel('Tasa de conversión y llamadas')\n",
    "plt.xlabel('Dias')\n",
    "\n",
    "ticks = np.arange(1,31,1)\n",
    "plt.xticks(ticks)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"El maximo de llamadas totales se encuentra concentrado en el día 20 y el cual es uno de los días con menor conversión.\")\n",
    "dia_cant[dia_cant['% Llamadas totales por dia'] == dia_cant['% Llamadas totales por dia'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"El maximo de % Conversion diario se encuentra en el 1er día del mes y el segundo pico se encuentra en el día 10. Podría tener sentido con los días en los que se cobra el sueldo\")\n",
    "dia_cant[dia_cant['% Conversion diario'] == dia_cant['% Conversion diario'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libero espacio\n",
    "del dia_cant\n",
    "del crooss_tab_dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables economicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colores = unique\n",
    "color_labels = df['default'].unique()\n",
    "rgb_values = sns.color_palette(\"Paired\", 2)\n",
    "#para usar la paleta paired por los labels \n",
    "color_map = dict(zip(color_labels, rgb_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, ncols = 1, figsize = (10,10))\n",
    "# Está en default?\n",
    "sns.countplot(x = 'default', data = df, ax = ax3, order = ['no', 'yes'], palette=df['default'].map(color_map))\n",
    "ax3.set_title('Default')\n",
    "ax3.set_xlabel('')\n",
    "ax3.set_ylabel('Cantidad')\n",
    "ax3.tick_params()\n",
    "\n",
    "# Tiene un prestamo hipotecario\n",
    "sns.countplot(x = 'housing', data = df, ax = ax1, order = ['no',  'yes'], palette=df['housing'].map(color_map))\n",
    "ax1.set_title('Housing')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Cantidad')\n",
    "ax1.tick_params()\n",
    "\n",
    "# Tiene un prestamo personal\n",
    "sns.countplot(x = 'loan', data = df, ax = ax2, order = ['no', 'yes'], palette=df['loan'].map(color_map))\n",
    "ax2.set_title('Loan')\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Cantidad')\n",
    "ax2.tick_params()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Default:\\n No tiene creditos en default'     , df[df['default'] == 'no']     ['default'].count(),\n",
    "              '\\n Tienen creditos en default:' , df[df['default'] == 'yes']    ['default'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Housing:\\n No tienen prestamos hipotecarios:'     , df[df['housing'] == 'no']     ['housing'].count(),\n",
    "              '\\n tTnen prestamos hipotecarios:' , df[df['housing'] == 'yes']    ['housing'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Loan:\\n No tienen prestamos personales:'     , df[df['loan'] == 'no']     ['loan'].count(),\n",
    "              '\\n Tienen prestamos personales:'    , df[df['loan'] == 'yes']    ['loan'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "sns.boxplot(y='balance', x='y', data=df, palette=paleta, ax = ax1)\n",
    "ax1.set_xlabel('Balance', fontsize=10)\n",
    "ax1.set_ylabel('Dinero', fontsize=10)\n",
    "ax1.set_title('Boxplot Balance', fontsize=10)\n",
    "ax1.tick_params(labelsize=10)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('1º Cuartil: ', df['balance'].quantile(q = 0.25))\n",
    "print('2º Cuartil: ', df['balance'].quantile(q = 0.50))\n",
    "print('3º Cuartil: ', df['balance'].quantile(q = 0.75))\n",
    "print('4º Cuartil: ', df['balance'].quantile(q = 1.00))\n",
    "print('La duración arriba de: ',df['balance'].quantile(q = 0.75) + \n",
    "                      1.5*(df['balance'].quantile(q = 0.75) - df['balance'].quantile(q = 0.25)), 'son outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece existir una política de llamadas. La dispersión del balance es muy grande. Sería interesante tener una idea para poder discretizar y separar entre clientes bajo, medio y alto. Pero cómo no sé en que tipo monetario está y no me puedo guiar por la distribución dejo este abordaje para posteriores estudios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estado civil y Educación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n",
    "cross_tab_marital = pd.crosstab(df.marital, df.y)\n",
    "cross_tab_marital.div(cross_tab_marital.sum(1).astype(float), axis=0).plot(kind='bar', stacked=False, color=['#fc8d59','#3288bd'], ax = ax1)\n",
    "ax1.set_xlabel('Estado Civil', fontsize=10)\n",
    "ax1.set_ylabel('% Conversion', fontsize=10)\n",
    "ax1.set_title('Conversion por Estado Civil', fontsize=10)\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "cross_tab_educacion = pd.crosstab(df.education, df.y)\n",
    "cross_tab_educacion.div(cross_tab_educacion.sum(1).astype(float), axis=0).plot(kind='bar', stacked=False, color=['#fc8d59','#3288bd'], ax = ax2)\n",
    "\n",
    "ax2.set_xlabel('Tipo de estudio', fontsize=10)\n",
    "ax2.set_ylabel('% Conversion', fontsize=10)\n",
    "ax2.set_title('Conversion  por tipo de estudio', fontsize=10)\n",
    "ax2.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libero espacio del disco\n",
    "del cross_tab_marital\n",
    "del cross_tab_educacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaña y contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacto = pd.crosstab(df.contact, df.y)\n",
    "contacto.div(contacto.sum(1).astype(float), axis=0).plot(kind='bar', stacked=False, color=['#fc8d59','#3288bd'],grid=False, figsize=(10, 5))\n",
    "plt.title(\"Conversion por modo de Contacto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.campaign.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.campaign.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaña = pd.crosstab(df.campaign, df.y)\n",
    "campaña.div(campaña.sum(1).astype(float), axis=0).plot(kind='bar', stacked=False, color=['#fc8d59','#3288bd'],grid=False, figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['y'],df['campaign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crooss_tab_camp = pd.crosstab(df['y'],df['campaign']).apply(lambda x: x/x.sum() * 100) \n",
    "crooss_tab_camp = crooss_tab_camp.transpose()\n",
    "camp = pd.DataFrame(df['campaign'].value_counts())\n",
    "camp['% Llamadas totales'] = camp['campaign']*100/camp['campaign'].sum()\n",
    "camp['% Conversion'] = crooss_tab_camp['yes']\n",
    "camp1 = camp\n",
    "camp1.loc['Total',\"% Llamadas totales\"]=  camp[\"% Llamadas totales\"].sum(axis=0) #suma el total de la columna que da 100% \n",
    "camp1['campañas'] = camp1.index\n",
    "camp1 = camp1.sort_values('% Conversion',ascending = False)\n",
    "camp1[camp1['% Conversion']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(camp1[camp1['% Conversion']>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las 32 campañas ejecutadas, sólo 14 superan el 1% de tasa de conversión. Recordemos que la tasa de conversión en este caso representa el ratio de clientes que realizaron el deposito sobre la cantidad que impacto esa campaña. Por ejemplo sólo se realizaron 3 llamadas de la campaña 24 y 1 de las llamadas fue una conversión. Habría que testear si esta tasa decae o se mantiene al aumentar la muestra.\n",
    "\n",
    "En el caso de la campaña 1, representa el 38% de la muestra y tiene una tasa de conversión de 13%. Por lo cual podríamos establecerla cómo nuestra campaña estrella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se muestra en el cuadro a continuación la campaña 11, 14, 15, 16, 18, 25, 19, 20, 28, 22, 32, 23,21,50,44,,29,30 y 31, deberían ser estudiadas para descartar, dado que latasa de conversión es menor al 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camp1[camp1['% Conversion']<1].sort_values('% Llamadas totales',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximo = camp1[camp1['% Conversion']>1]\n",
    "maximo['campañas'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(maximo, x=\"% Llamadas totales\", y=\"% Conversion\", color=\"campañas\",\n",
    "                 size='% Llamadas totales', hover_data=['campañas'],\n",
    "                title=\"Campañas en función de tasa de Conversion y tasa de llamadas\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del maximo\n",
    "del campaña\n",
    "del camp1\n",
    "del camp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Logistica\n",
    "\n",
    "Recordemos que nuestro objetivo es:\n",
    "* Repetir una o más campañas en el transcurso de los siguientes 18 meses.\n",
    "* Maximizar la tasa de conversión de las mismas y entender los factores que influyen en esta tasa.\n",
    "\n",
    "Por lo tanto nos interesa mantener todos las variables presentes, en caso de hacer un modelo de predicción de clientes deberíamos no elegir variables que no van a estar presentens en nuestra base de datos, cómo duration.\n",
    "\n",
    "Ópte por un Regresión logística para tener interpretabilidad de los resultados, entendiendo a los coeficientes significativos cómo la probabilidad de ocurrencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecion de variables por Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformé a objetos las variables día, mes y campaña que por defecto las tomaba cómo entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat1 = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
    "       'day', 'month', 'campaign', 'poutcome',\"grupo_edad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat1:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "    data1=data.join(cat_list)\n",
    "    data=data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars=data.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat1]\n",
    "data_final=data[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Función para encodear\n",
    "def encoder(df, cat):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    clases = []\n",
    "    for i in cat:\n",
    "        df[i]=le.fit_transform(df[i]) \n",
    "        clases.append(le.classes_)\n",
    "    return df, clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final, target = encoder(data_final,\"y\")\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_final.drop(['age'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_final.drop(['y'],axis=1)\n",
    "y=data_final.y\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = list(feat_importances.nlargest(10).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars=data_final.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i in columnas]\n",
    "x=data_final[to_keep]\n",
    "x.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote: Oversampling\n",
    "El algoritmo SMOTE funciona en 4 sencillos pasos:\n",
    "Elija un vector de entrada de clase minoritaria\n",
    "Encuentre sus k vecinos más cercanos (k_neighbors se especifica como un argumento en la función SMOTE ())\n",
    "Elija uno de estos vecinos y coloque un punto sintético en cualquier lugar de la línea que une el punto en consideración y su vecino elegido\n",
    "Repita los pasos hasta que los datos estén equilibrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "y = data_final.y\n",
    "\n",
    "smote = SMOTE(random_state=100)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "columns = x_train.columns\n",
    "\n",
    "smote_data_x,smote_data_y = smote.fit_sample(x_train, y_train)\n",
    "smote_data_x = pd.DataFrame(data=smote_data_x, columns=columns)\n",
    "smote_data_y = pd.DataFrame(data=smote_data_y, columns=['y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanceo de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Tamaño de la data antes de hacer oversampling: ', len(x_train))\n",
    "print('Data oversampleada: ', len(smote_data_y))\n",
    "print('Clientes que no depositaron: ', len(smote_data_y[smote_data_y['y'] == 0]))\n",
    "print('Clientes que depositaron: ', len(smote_data_y[smote_data_y['y'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = smote_data_x\n",
    "training_y = smote_data_y['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(training_x)\n",
    "logm2 = sm.GLM(training_y,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coeficiente de balance es no representativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\dot{P(Deposito)} & = \\beta_0+\\beta_1 *balance+ \\beta_2 *duration  + \\beta_3 *pday+\\beta_4 *previous\n",
    "\\beta_5 *maritalmarried+\\beta_6 *month_10+\\beta7 *campaign_1+\\beta8 *campaign2+\\beta9 *poutcomesucess +\\beta910* grupo_edad_30\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_x, training_y,\n",
    "                                                    test_size=0.3, random_state=100)\n",
    "\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "print('Accuracy on test set: ', regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print('True Positive: ', confusion[0][0], 'False Negative: ', confusion[0][1])\n",
    "print('False Positive: ', confusion[0][1], 'True Negative: ', confusion[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Precision, recall, F-measure ve support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, predictions)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, regressor.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area=%0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('ROC-Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es una herramienta común utilizada con clasificadores binarios. La línea de puntos representa un clasificador puramente aleatorio; un buen clasificador permanece lo más lejos posible de esa línea (hacia la esquina superior izquierda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res.predict(X_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Converted':training_y.values, 'Converted_prob':y_train_pred})\n",
    "y_train_pred_final['ID'] = training_y.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Converted_prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "from sklearn import metrics\n",
    "# Matriz de confusión \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busco puntos de corte\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=cm1.sum()\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El punto de corte se da en la interseccion de sensitivity  y specificity\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_prob.map( lambda x: 1 if x > 0.48 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Lead_Score'] = y_train_pred_final.Converted_prob.map( lambda x: round(x*100))\n",
    "\n",
    "#calculo la accuracy del modelo ahora\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sensitivity\n",
    "Recall = TP / float(TP+FN)\n",
    "print(f\"Recall: {Recall.round(2)}\")\n",
    "#specificity\n",
    "specificity = TN / float(TN+FP)\n",
    "print(f\"Specificity: {specificity.round(2)}\")\n",
    "# false postive rate \n",
    "fprt = FP/ float(TN+FP)\n",
    "print(f\"False postive rate : {fprt.round(2)}\")\n",
    "# Positive predictive value \n",
    "ppv = TP / float(TP+FP)\n",
    "print(f\"Precision: {ppv.round(2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confusión\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Chequeo Precision pero con la matriz de confusion\n",
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Chequeo el valor de Recall en matriz\n",
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}